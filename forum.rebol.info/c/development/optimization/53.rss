<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:discourse="http://www.discourse.org/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Optimization - AltRebol</title>
    <link>https://forum.rebol.info/c/development/optimization/53</link>
    <description>Topics in the &#39;Optimization&#39; category This is a category for discussing performance and optimization ideas.</description>
    
      <lastBuildDate>Mon, 18 Oct 2021 06:45:29 +0000</lastBuildDate>
      <atom:link href="https://forum.rebol.info/c/development/optimization/53.rss" rel="self" type="application/rss+xml" />
        <item>
          <title>Simple Objects vs. What The People Want</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>Ren-C has a more streamlined version of how R3-Alpha implemented simple OBJECT!s, but it's really mostly the same <em>(though MODULE! has changed significantly)</em></p>
<p>An OBJECT! is just two parallel lists, which I have called the <strong>"keylist"</strong> and the <strong>"varlist"</strong>.</p>
<p>So if you say something like:</p>
<pre><code>obj: make object! [
    x: 1 + 2
    y: 10 + 20
]
</code></pre>
<p>You will get:</p>
<pre><code>keylist: {symbol(x) symbol(y)}
varlist: [*V0* 3 30]
</code></pre>
<p>The first slot in a varlist is used for some tracking information.  So:</p>
<ul>
<li>
<code>keylist[0]</code> is the key for <code>varlist[1]</code>
</li>
<li>
<code>keylist[1]</code> is the key for <code>varlist[2]</code>
</li>
</ul>
<h2>You Get A New Keylist With Every MAKE OBJECT!</h2>
<p>Nothing in the system goes around looking for common patterns in your object creation to notice that you've made several objects with the same keys.</p>
<pre><code>collect [
    count-up i 1000 [
        keep make object! [x: i * 10, y: i * 20]
    ]
]
</code></pre>
<p>You just made 1000 objects, and all of them have their own copy of the keylist <code>{symbol(X) symbol(Y)}</code>.  Ren-C made this overhead cost less than 1/4 as much as R3-Alpha, but it's still kind of lame.</p>
<p><strong>The only way you avoid making a new keylist is if you do object inheritance.</strong></p>
<pre><code>point!: make object! [x: y: null]
collect [
    count-up i 1000 [
        keep make point! [x: i * 10, y: i * 20]
    ]
]
</code></pre>
<p>This time, there's 1000 objects all sharing a single keylist.</p>
<p><strong>If you expand keys at all, that will result in a new keylist...</strong></p>
<p>You spoil the optimization if you put anything additional in your derived object:</p>
<pre><code>point!: make object! [x: y: null]
collect [
    count-up i 1000 [
        keep make point! [x: i * 10, y: i * 20, z: i * 30]
    ]
]
</code></pre>
<p>There's no inheritance mechanism that makes use of the common sublist.  So this puts you at <em>1001</em> keylists, because your keylist for the original point! never gets used.</p>
<p><strong>Object Expansion via APPEND disconnects shared keylists</strong></p>
<p>R3-Alpha allowed you to add fields to an object.  If you did so, you would lose any sharing that it had taken advantage of before.</p>
<pre><code>p: make point! [x: 10 y: 20]  ; reuses point!'s keylist
append p [z: 30]  ; oop, not anymore...gets its own keylist.
</code></pre>
<p><strong>Comparisons Are Difficult</strong></p>
<p>Because there's no global mechanism of canonization of keylists, you get entirely different-looking objects by creating the fields in different orders.</p>
<pre><code>obj1: make object! [x: 10 y: 20]
obj2: make object! [y: 20 x: 10]
</code></pre>
<p>These objects have been considered to be not equal historically.  Because comparisons are done by walking the fields in order.  So obj1 &lt;&gt; obj2 in this case.</p>
<p>However, if you create an object via inheritance so it shares a keylist, that will standardize the order of the fields:</p>
<pre><code>point1: make point! [x: 10 y: 20]
point2: make point! [y: 20 x: 10]
</code></pre>
<p>Here we will have point1 = point2, since their shared keylist forces the order of x and y to whatever it was in POINT!.</p>
<h2>There Are Fancier Ways Of Dealing With This</h2>
<p><strong>If you're willing to say that the order of keys in objects shouldn't matter...</strong> then you can rethink the data structures to exploit commonalities in the patterns of keys that are created.</p>
<p>The V8 JavaScript engine approaches this with <strong><a href="https://richardartoul.github.io/jekyll/update/2015/04/26/hidden-classes.html">Hidden Classes</a></strong>.</p>
<p>But there's really always some other way of approaching the problem.  The way modules work in "Sea of Words" is an example of a structure that seems to work reasonably well for modules--but wouldn't work as well for lots of little objects.</p>
<h2>Today's FRAME! Depends On This Non-Fancy Way</h2>
<p>Right now, when a native runs it does so with a concept of the order of the arguments and refinements that gets baked into the C code directly.  IF knows that the condition is argument 1 and that the branch is argument 2, and it looks directly in slots 1 and 2 of the varlist of the frame to find those variables.</p>
<p>This is pretty foundational to the idea of the language, and is part of what gives it an appealing "simple-ness".</p>
<p>Ren-C has come along and permitted higher level mechanisms like specialization and adaptation, but everything is always getting resolved in a way that each step in a function's composition works on putting information into the exact numbered slot that the lower levels expect it to be in.</p>
<h2>Binding Has Depended On This Non-Fancy Way</h2>
<p>A premise in Rebol has been that you can make a connection between a variable and an object that has a key with the name of that variable, and once that connection is made it will last.  This rule is why there's been dodginess about deleting keys in objects or rearranging them...and why R3-Alpha permits adding new variables but not removing any.</p>
<pre><code> obj: make object! [x: 10 y: 20]
 code: [x + y]
 bind code obj
</code></pre>
<p>If you write something like the above, you are annotating the X inside of CODE with (obj field <span class="hashtag">#1</span>), and the Y inside of CODE with (obj field <span class="hashtag">#2</span>).  So nothing can happen with obj that can break that.</p>
<p><strong>This isn't strictly necessary.</strong>  It could have annotated X and Y with just (obj) and then gone searching each time it wanted to find it.  This would permit arbitrary rearrangement of OBJ, inserting and removing keys.  It could even remove X or Y and then tell you it couldn't find them anymore.</p>
<p>There are compromises as well.  The binding could be treated as a potentially fallible cache...it could look in that slot position (if it's less than the total keylist size) and see if the key matched.  If not, it could fall back on searching and then update with the slot where it saw the field.</p>
<p>(Of course this means you have to look at the keylist instead of just jumping to where you want to be in the varlist, and locality is such that they may not be close together; so having to look at the keylist <em>at all</em> will bring you a slowdown.)</p>
<h2>But What Is The Goal, Here?</h2>
<p>I've mentioned how the FRAME! design pretty much seems to go along well with the naive ordering of object fields.</p>
<p>I guess this is where your intuition comes in as to what represents "sticking to the rules of the game".  <em>And I think that hardcoding of positions into the executable of where to find the argument cells for natives is one of the rules.</em></p>
<p>This suggests that all functions hardcode the positions of their arguments--even usermode functions.  I'm okay with this.</p>
<p>So then we get to considering the question about OBJECT!.</p>
<ul>
<li>
<p>A lot of languages force you to predefine the structure of an object before creating instances.  And defining that structure is a good place to define its interfaces.  If Rebol wants to go in a more formal direction (resembling a Rust/Haskell/C++) then you might suggest you <em>always</em> make a base structure...and you can only have the fields named in it.</p>
</li>
<li>
<p>Other languages (like JavaScript) are more freeform, and as mentioned can look for the relationships after-the-fact.  Order of fields does not matter.</p>
</li>
</ul>
<p>It's clear that Rebol's userbase so far are people who would favor better implementation of the JavaScript model over going to more strictness.  I think there'd be a pretty good reception of a model where you could create objects with <strong>{...}</strong> and where fields could be added or removed as people saw fit.  If behind-the-scenes the system was optimizing access to those objects, that would presumably be preferable to this idea that you had to be responsible for declaring prototypes to get efficiencies (that would instantly disappear if you added another field).</p>
<p>But the mechanics definitely get more complicated.  :-/</p>
            <p><small>8 posts - 3 participants</small></p>
            <p><a href="https://forum.rebol.info/t/simple-objects-vs-what-the-people-want/1745">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/simple-objects-vs-what-the-people-want/1745</link>
          <pubDate>Mon, 18 Oct 2021 06:45:29 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1745</guid>
          <source url="https://forum.rebol.info/t/simple-objects-vs-what-the-people-want/1745.rss">Simple Objects vs. What The People Want</source>
        </item>
        <item>
          <title>Changing Strategies on Avoiding Stdio Inclusion</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>Among the battles that Rebol picked, one was to not become dependent on the IO and formatting constructs of libc.  So you could build an interpreter without the logic that is behind <strong>printf("Hello %s, your Score is %d\n");</strong></p>
<p>Ren-C embraced this and tried to enforce it by causing compile-time errors when stdio.h was included in release builds.  Over time this has turned out to be a non-viable strategy for accomplishing the intent.</p>
<p>Modern C compilers have more or less assumed that if you include one header you want to include them all.  So if you <strong><code>#include &lt;string.h&gt;</code></strong> you're likely to get all of <strong><code>&lt;stdio.h&gt;</code></strong> too.</p>
<p>And as it happens, while we don't need printf(), we now do need some definitions out of stdio in some files.</p>
<p><strong>We still should keep an eye on included functions, but that oversight needs to shift from the compiler level to the linkage level</strong>.</p>
<p>Here was some of the trickery used to try and keep stdio.h out of release builds:</p>
<pre><code>//
// DISABLE STDIO.H IN RELEASE BUILD
//
// The core build of Rebol published in R3-Alpha sought to not be dependent
// on &lt;stdio.h&gt;.  Since Rebol has richer tools like WORD!s and BLOCK! for
// dialecting, including a brittle historic string-based C "mini-language" of
// printf into the executable was a wasteful dependency.  Also, many
// implementations are clunky:
//
// http://blog.hostilefork.com/where-printf-rubber-meets-road/
//
// To formalize this rule, these definitions will help catch uses of &lt;stdio.h&gt;
// in the release build, and give a hopefully informative error.
//
#if defined(NDEBUG) &amp;&amp; !defined(DEBUG_STDIO_OK)
    //
    // `stdin` is required to be macro https://en.cppreference.com/w/c/io
    //
    #if defined(__clang__)
        //
        // !!! At least as of XCode 12.0 and Clang 9.0.1, including basic
        // system headers will force the inclusion of &lt;stdio.h&gt;.  If someone
        // wants to dig into why that is, they may...but tolerate it for now.
        // Checking if `printf` and such makes it into the link would require
        // dumping the library symbols, in general anyway...
        //
    #elif defined(stdin) and !defined(REBOL_ALLOW_STDIO_IN_RELEASE_BUILD)
        #error "&lt;stdio.h&gt; included prior to %sys-core.h in release build"
    #endif

    #define printf dont_include_stdio_h
    #define fprintf dont_include_stdio_h
#else
    // Desire to not bake in &lt;stdio.h&gt; notwithstanding, in debug builds it
    // can be convenient (or even essential) to have access to stdio.  This
    // is especially true when trying to debug the core I/O routines and
    // unicode/UTF8 conversions that Rebol seeks to replace stdio with.
    //
    // Hence debug builds are allowed to use stdio.h conveniently.  The
    // release build should catch if any of these aren't #if !defined(NDEBUG)
    //
    #include &lt;stdio.h&gt;

    // NOTE: F/PRINTF DOES NOT ALWAYS FFLUSH() BUFFERS AFTER NEWLINES; it is
    // an "implementation defined" behavior, and never applies to redirects:
    //
    // https://stackoverflow.com/a/5229135/211160
    //
    // So when writing information you intend to be flushed before a potential
    // crash, be sure to fflush(), regardless of using `\n` or not.
#endif
</code></pre>
<p>Here are some comments on how the C++ <strong><code>&lt;string&gt;</code></strong> header on MSVC pulled in formatting that pulled in string.h (aka. <strong><code>&lt;cstring&gt;</code></strong> in C++ terms).</p>
<pre><code>/*
 * If using C++, variadic calls can be type-checked to make sure only
 * legal arguments are passed.  It also means one can pass literals
 * and have them coerced (e.g. integer =&gt; INTEGER! or bool =&gt; LOGIC!).
 *
 * Note: In MSVC, `#include &lt;string&gt;` will pull in `&lt;xstring&gt;` that
 * then sucks in `&lt;iosfwd&gt;` which brings in `&lt;cstdio&gt;`.  This means
 * that including the release version of %sys-core.h will see an
 * inclusion of stdio that it doesn't want.  Bypass the assertion
 * for this case, and hope the C build maintains dependency purity.
 */
#ifdef TO_WINDOWS
    #define REBOL_ALLOW_STDIO_IN_RELEASE_BUILD  // ^^-- see above
#endif
</code></pre>
<h2>Again, not giving up, just changing tactics...</h2>
<p>In fact, it's really better to be looking at the binary for bloat anyway.  You can write innocuous lines of source and find that brought in all kinds of things in the compiler.  So going by the source isn't the best idea.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://forum.rebol.info/t/changing-strategies-on-avoiding-stdio-inclusion/1685">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/changing-strategies-on-avoiding-stdio-inclusion/1685</link>
          <pubDate>Thu, 26 Aug 2021 13:24:52 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1685</guid>
          <source url="https://forum.rebol.info/t/changing-strategies-on-avoiding-stdio-inclusion/1685.rss">Changing Strategies on Avoiding Stdio Inclusion</source>
        </item>
        <item>
          <title>Sea of Words is now in Beta (or something?)... Some Numbers</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>I've gotten Sea of Words through the test suite and Bootstrap...and running the scenarios that have GitHub Actions (rebol-httpd, rebol-odbc, rebol-whitespacers.)  And I got it working in the web console too, of course!</p>
<p><em>(Note: If the web console seems sluggish these days don't blame Sea of Words...I started using UPARSE in it, and right now UPARSE is in full-on experimental mode.  It's a beast, so using it at all--even on trivial samples--will be resource intensive.)</em></p>
<h1>Some Easy-To-Get Numbers For The Moment</h1>
<p><strong>These numbers should be taken with a grain of salt...</strong> they don't measure everything, and some things shift around in ways that are hard to quantify.  But they're better than nothing.</p>
<p>(Note: I actually had to fix a bug in the evaluation count that was giving wild answers.  R3-Alpha lacked a double-check on its optimized method of incrementing the total evaluation count without needing to so every time in the loop...)</p>
<h2>Prior to Sea of Words</h2>
<p>Here is a report from a freshly booted desktop build on Windows, which avoids trying to read the executable into memory:</p>
<pre><code>&gt;&gt; stats/profile
== make object! [
    evals: 123702
    series-made: 53630
    series-freed: 27122
    series-expanded: 728
    series-bytes: 3460161
    series-recycled: 25447
    made-blocks: 33403
    made-objects: 191
    recycles: 3
]
</code></pre>
<h2>After Sea of Words</h2>
<pre><code>&gt;&gt; stats/profile
== make object! [
    evals: 138386
    series-made: 72860
    series-freed: 39697
    series-expanded: 706
    series-bytes: 3270669
    series-recycled: 20856
    made-blocks: 52054
    made-objects: 221
    recycles: 3
]
</code></pre>
<p>On the bright side, <strong>Sea of Words is not only a watershed moment in binding/modules, it's also saving 189K or so of memory</strong>, even just here in its first debut.</p>
<p>You may be wondering why there are so many more blocks.  The answer is that they're very <em>tiny</em> optimized stub blocks, used to hold individual variables that are floating in the "sea".  This is expected and purposeful.  As shown, the total memory use went down...</p>
<h2>This is Really Only A Beginning</h2>
<p>While the abilities that just came into play are a tremendous step for making a "real" and usable module system, there is significantly more left.  I'll be posting more on those issues after some <img src="https://forum.rebol.info/images/emoji/twitter/zzz.png?v=9" title=":zzz:" class="emoji" alt=":zzz:"></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://forum.rebol.info/t/sea-of-words-is-now-in-beta-or-something-some-numbers/1678">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/sea-of-words-is-now-in-beta-or-something-some-numbers/1678</link>
          <pubDate>Sun, 22 Aug 2021 11:45:46 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1678</guid>
          <source url="https://forum.rebol.info/t/sea-of-words-is-now-in-beta-or-something-some-numbers/1678.rss">Sea of Words is now in Beta (or something?)... Some Numbers</source>
        </item>
        <item>
          <title>Beating REPEND: A New Parameter Convention?</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>When you do an <strong>append a reduce b</strong>, the REDUCE generates a new series... let's call it <strong>rb</strong>.  Then <strong>rb</strong> is spliced into <strong>a</strong>.  And then <strong>rb</strong> needs to be GC'd.</p>
<p>The idea behind <strong>repend a b</strong> is that you never make <strong>rb</strong>.  Instead, expressions are evaluated one by one and put onto <strong>a</strong> as you go.  The savings are twofold...reduced memory overhead and reduced tax on the GC by not making extra series nodes.</p>
<p>That might sound like a great savings, but here is a heated debate in Red about the questionable benefit of REPEND (as well as /INTO):</p>
<p><a href="https://github.com/red/red/issues/3340">https://github.com/red/red/issues/3340</a></p>
<p>I guess I'm halfway on DocKimbel's side there...in that if REPEND isn't showing a benefit it's probably more to do with a bug in REPEND vs. that the idea doesn't represent a savings.</p>
<p>But I <em>hate</em> the word REPEND.  Things like REMOLD are double monstrous, and REFORM?  Give me a break.  These make a terrible impression.</p>
<p>More generally, I don't like the idea that every function would have to come in two flavors and create anxiety on the part of the caller as to if they're using the optimized one or not.  I'd like any optimization to be more "under the hood" so the caller doesn't have to fret about it.</p>
<p>This got me to thinking...</p>
<h2>A New Voodoo for GET-params!</h2>
<p>Let's imagine that we have a new rule for params that look like GET-WORD!:</p>
<ul>
<li>
<p>If the argument is a GET-XXX!, it is passed literally</p>
</li>
<li>
<p>If the argument is anything else, it is evaluated normally and the product is passed in with one quoting level added.</p>
</li>
</ul>
<p>Here's an example definition</p>
<pre><code>appender: func [
    block [block!]
    :value [any-value!]
][
   print ["Block is" mold block]
   print ["Value is" mold value]
   if get-block? value [
       append block reduce as block! value
   ] else [
       append block unquote value
   ]
]
</code></pre>
<p>Let's look at some concrete examples:</p>
<pre><code>&gt;&gt; appender [1 2 3] 2 + 2
Block is [1 2 3]
Value is '4
== [1 2 3 4]

&gt;&gt; data: [[a b c] [d e f]]
&gt;&gt; appender [1 2 3] second data
Block is [1 2 3]
Value is '[d e f]
== [1 2 3 d e f]

&gt;&gt; appender [1 2 3] :[10 + 20 100 + 200]
Block is [1 2 3]
Value is :[10 + 20 100 + 200]  ; not quoted!
== [1 2 3 30 300]
</code></pre>
<p>At the source level, the user doesn't really have to worry about the parameter convention.  They get the same outcome as if the REDUCE had been done by the evaluator, but the APPENDER becomes complicit.</p>
<p>And look what happens if the GET-BLOCK! is in a variable...</p>
<pre><code>&gt;&gt; data: the :[10 + 20 100 + 200]
&gt;&gt; appender [1 2 3] data
Block is [1 2 3]
Value is ':[10 + 20 100 + 20]
** Error: Cannot append evaluative items...
</code></pre>
<p><strong>A ha!</strong> We could tell that this was an evaluative get-block product, and not meant to participate in our little trick.  <em>(Erroring is actually the right answer here, you would need to use <strong>only data</strong> or <strong>^data</strong> or <strong>quote data</strong> etc. to APPEND an evaluative GET-BLOCK! under the new rules.)</em></p>
<p>This is neat, because it means users can express intention to reduce at the callsite...and it is something that you can optimize on an as-needed basis.</p>
<h2>As One Would Expect, There Are Some Glitches...</h2>
<p>There are some seeming semantic glitches when a function takes these and they're not the last parameter, where you might see variations along the lines of:</p>
<pre><code> &gt;&gt; takes-first-args-normally :[elide print "A", 1 + 2] (print "B", &lt;x&gt;)
 A
 B
 3
 &lt;x&gt; 

&gt;&gt; takes-first-arg-specially: :[elide print "A", 1 + 2] (print "B", &lt;x&gt;)
A
B
&lt;x&gt;
3
</code></pre>
<p>Basically: <strong>If you somehow relied on side effects happening in left-to-right parameter order at the callsite, then moving the REDUCE of any parameters other than the last one into the body of the operation will change that order.</strong></p>
<p>This is nothing new for this line of thinking in optimization: imagine if APPEND and REPEND took their arguments in the reverse order, so that the block wasn't the last item.  You couldn't just blindly substitute APPEND REDUCE for REPEND in that case, if you were dependent on argument-ordering effects...if there was an evaluation in the first parameter's reduction that was needed for the second parameter.</p>
<p>But the difference is that the person editing APPEND REDUCE =&gt; REPEND made  a change at the callsite.  If you change the parameter convention and don't touch the callsites--with the intent that they stay working and you're just adding an optimization--it starts to matter.</p>
<p>We have some control here, though!  We can define how GET-BLOCK!s act as arguments to function calls, and we can say that they don't actually perform their REDUCE until the function executes.  That leaves breathing room for people who wish to add the optimization later...knowing they won't break the expectations.</p>
<p><em>Whew, that solves that problem!  Good thing it's the only one!  Oh, no, wait...</em>  <img src="https://forum.rebol.info/images/emoji/twitter/face_with_head_bandage.png?v=9" title=":face_with_head_bandage:" class="emoji" alt=":face_with_head_bandage:"></p>
<h2>Not All REPEND Operations Take Literal Blocks</h2>
<p>You see <strong>repend data [...]</strong> a lot of the time, but there's also <strong>repend block1 block2</strong>.</p>
<p>So <strong>append data :[...]</strong> can be finessed as an optimization for the first case, but doesn't solve the second.</p>
<p>To shore it up, we'd have to say that <strong><code>:(...)</code></strong> means "reduce the result of what's in the expression".</p>
<pre><code>&gt;&gt; :(reverse [1 + 2 10 + 20])  ; -&gt; :[20 + 10 2 + 1]
== [30 3]
</code></pre>
<p>This way, we could actually pass the APPEND an expression to reduce the product of.  We'd need to do the evaluation at the moment we passed the parameter (I think), and then alias it as a GET-BLOCK!, so:</p>
<pre><code>&gt;&gt; appender [1 2 3] :(reverse [1 + 2 10 + 20])
Block is [1 2 3]
Value is :[20 + 10 2 + 1]
== [1 2 3 3 30]
</code></pre>
<h2>Where Are GET-WORD!, GET-PATH!, GET-TUPLE! in all of this?</h2>
<p>We don't have GET-WORD! mean "reduce the product of fetching the word":</p>
<pre><code>&gt;&gt; block: [1 + 2]

&gt;&gt; :block
== [1 + 2]  ; not [3]
</code></pre>
<p>But it seems it would be inconsistent to not put these other GET-XXX! types into the family of parameters that are captured as-is.  So the above code would get this behavior:</p>
<pre><code>&gt;&gt; appender [1 2 3] :foo
Block is [1 2 3]
Value is :foo
** Error: Cannot append evaluative items...
</code></pre>
<p>Instead of a REDUCE it would need a GET.  But this makes a good argument for why REDUCE of a GET-WORD! should work as a word fetch, for generality... it makes routines like this easier to write correctly.</p>
<p>I don't think it's worth shuffling the symbols around so that <strong>:foo</strong> does a reduce and we pick something else for GET.  It seems to me that <strong>:(foo)</strong> is fine enough.</p>
<p>But even though GET-WORD! won't run arbitrary code, you can be impacted by ordering problems, where someone might pass a <strong>:foo</strong> argument and then in the next parameter change the value of foo.  Hence for consistency, we'd be saying that normal parameters would likely have to delay their get of foo until all the parameters were given...this way you could change the parameter convention without affecting callsites.</p>
<p>But likely the best way to go about that would be to protect the word from modification:</p>
<pre><code>&gt;&gt; some-func :foo (foo: 20, &lt;arg&gt;)
** Error: FOO captured by GET-WORD! in parameter slot, can't modify
      while gathering arguments
</code></pre>
<h2>I'm Probably Over-Worrying About It</h2>
<p>...these protection mechanisms I mention in order to make it painless to change a parameter convention are not likely suited to being the kind of concern that applies.</p>
<p>But it's good to articulate what the limits of a design are...</p>
            <p><small>3 posts - 1 participant</small></p>
            <p><a href="https://forum.rebol.info/t/beating-repend-a-new-parameter-convention/1673">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/beating-repend-a-new-parameter-convention/1673</link>
          <pubDate>Thu, 19 Aug 2021 22:29:50 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1673</guid>
          <source url="https://forum.rebol.info/t/beating-repend-a-new-parameter-convention/1673.rss">Beating REPEND: A New Parameter Convention?</source>
        </item>
        <item>
          <title>Paring Down the Boot Block Symbol Table</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>Rebol has historically had a file called %words.r, that points out words that the C code would like to be able to recognize quickly by ID numbers.</p>
<p>So if you want to write something like C code for PARSE that recognizes keywords, you might write something like:</p>
<pre><code>switch (VAL_WORD_ID(word)) {
  case SYM_SOME:
      // code for implementing a some rule..
     break;

 case SYM_WHILE:
     // code for implementing a while rule...
    break;
}
</code></pre>
<p>etc.  In C you can only switch() on integers, not pointers.  So these SYM_XXX values have to be agreed upon by the C code and the symbol-loading subsystem.</p>
<p>Some tricks depend on actual ordering of these symbols, or ranges of them.  But most of the time, it doesn't really matter.</p>
<p>If something doesn't have a symbol ID, then you have to do slower creations and comparisons by string... or create your own instance of a symbol and then compare to that symbol by pointer.</p>
<h2>Another Idea: Nix the Table And Trust Determinism</h2>
<p>Right now the way the loading process goes, you have your list of words in %words.r and they count up.  Let's imagine:</p>
<pre><code>apple
banana
orange
...
</code></pre>
<p>So apple becomes SYM_APPLE = 1, banana becomes SYM_BANANA = 2, orange becomes SYM_ORANGE = 3, etc.</p>
<p>The beginning of the boot block has these words in a block, and then stuff using them</p>
<pre><code>[
    [apple banana orange ...]
    [foo: func [] [eat 'apple] peel orange/banana ...]
    ...
]
</code></pre>
<p>Each of those word cells takes up 4 platform pointers, so 32 bytes apiece.  Which is a fair amount to pay to convey the contract between the C code and the interpreter that APPLE needs to have an associated shorthand of 1, BANANA needs a shorthand of 2, etc.</p>
<p><strong>But if you don't care about the values, why not use whatever the value was organically?</strong></p>
<p>Imagine that list at the beginning wasn't there:</p>
<pre><code>[
    [foo: func [] [eat 'apple] peel orange/banana ...]
    ...
]
</code></pre>
<p>The scanner can still give a number to basically every unique word that's in the boot block if it wants to.  It would just come out in a different order... FOO would be 1, FUNC would be 2, EAT would be 3, APPLE would be 4 etc.</p>
<p>You don't necessarily want a giant C file of SYM_XXX for absolutely every word used in the mezzanine.  But what could be done here would be that %words.r would be an indication of <em>registering interest</em> in what value a loaded word ultimately got.</p>
<p><strong>But how do you know what order the scanner is going to visit words in?</strong>  Well, you don't...and you get a chicken and an egg problem.  You can't build the executable to scan without the SYM_XXX numbers.</p>
<p><strong>...unless the scanner was a separate library that could be linked and run standalone...</strong>  If the scanner was factored you could have one compile step that built it, and then linked it into a small executable just for the purposes of generating an enum of SYM_XXX values for a particular boot block.</p>
<p>Not something likely to happen this year (or this lifetime), but... I thought it was interesting to think that if the code were a little more self-aware, the array of words in the boot block could be cut way back to only words that required having sequential integer numbers for some optimization.  <em>(Or <em>specific</em> numbers for some optimization...the only case of that is that the spelling of datatype words line up with the enum value of the datatype in the system.)</em></p>
<h2>Another Related Idea: An Internet Registry for WORD &lt;=&gt; ID</h2>
<blockquote>
<p>Note: This concept is actually contentious with the above...</p>
</blockquote>
<p>If we really wanted to (and weren't concerned about size), we could get a dictionary off the Internet of the 65535 most common words, and number them all in advance.  Then we could tell people who write C extensions that they can use those numbers in their code, so their extensions would be faster if they happened to want to deal with that spelling of that word.</p>
<p>Except then the r3.exe would have a big fat dictionary inside it with a list of strings that extensions may never use.</p>
<p>But putting the dictionary in isn't actually necessary.  If you trust extension authors to be true to the string table, then just publish the table on the Internet in an agreed upon place.  All an extension has to when it gets loaded is to supply the list of strings and numbers out of that table it wants to use.  You only pay for the entries in the table you need...and it doesn't cost any more than having those strings would anyway.</p>
<p>The system could then reconcile and notice if one extension said "banana" is 1020 and another said "banana" is 304.  It could just say one of those extensions is wrong and refuse to load them.  It can do so without r3.exe needing to store the string "banana" or information about it being 304 intrinsically.</p>
<p><em>The reason I say it's contentious is because changes in the boot block would shuffle the symbol IDs around.  This means the deterministic (but changing) approach would create symbol values that would force extensions to be recompiled, while a committed database of numbers would not.</em></p>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://forum.rebol.info/t/paring-down-the-boot-block-symbol-table/1671">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/paring-down-the-boot-block-symbol-table/1671</link>
          <pubDate>Thu, 19 Aug 2021 00:59:26 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1671</guid>
          <source url="https://forum.rebol.info/t/paring-down-the-boot-block-symbol-table/1671.rss">Paring Down the Boot Block Symbol Table</source>
        </item>
        <item>
          <title>About the Optimization category</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>This is a category for discussing performance and optimization ideas.</p>
<p>Though remember the very important <strong>Rules For Optimizations (at least, the Ones Make Code Less Clear)</strong>:</p>
<h1>Rule <span class="hashtag">#1:</span> Don't do it.</h1>
<h1>Rule <span class="hashtag">#2:</span> (Experts only!) Don't do it...yet.</h1>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://forum.rebol.info/t/about-the-optimization-category/1670">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/about-the-optimization-category/1670</link>
          <pubDate>Thu, 19 Aug 2021 00:15:43 +0000</pubDate>
          <discourse:topicPinned>Yes</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1670</guid>
          <source url="https://forum.rebol.info/t/about-the-optimization-category/1670.rss">About the Optimization category</source>
        </item>
        <item>
          <title>Web Build Performance Stats</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>I resurrected the "stats" function to get some metrics.  It's actually a good example of how nicely Ren-C can improve things:</p>
<ul>
<li>
<p><a href="https://github.com/rebol/rebol/blob/25033f897b2bd466068d7663563cd3ff64740b94/src/core/n-system.c#L129">Here's the code for stats in R3-Alpha</a> (which references an object prototype <a href="https://github.com/rebol/rebol/blob/25033f897b2bd466068d7663563cd3ff64740b94/src/boot/sysobj.r#L255">defined elsewhere in sysobj.h</a>, and you can also see that all you see in this file of the function spec is REBNATIVE(stats))</p>
</li>
<li>
<p><a href="https://github.com/metaeducation/ren-c/blob/de62515f95ce335c07622ef51218d5da9e938a12/src/core/d-stats.c#L56">Here's that in Ren-C</a>, and the maintainability advantages should be obvious.  The distinction of counting natives didn't exist in the same fashion as before, so it was deleted, but we could do that kind of thing another way.</p>
</li>
</ul>
<p>In any case, running the statistics between R3-Alpha and Ren-C are going to show <em>a lot</em> more series and memory use in Ren-C.  The main reasons are:</p>
<ul>
<li>
<p>There's a Windows encapping issue that it reads the whole executable into memory to probe it for resource sections.  This is especially crazy for debug builds.  I'd raised this as an issue for Shixin to look at but forgot about it.</p>
</li>
<li>
<p><strong>Function frames do not use the data stack, and instead the arguments of functions are stored in individual arrays.</strong>  While there are some optimizations to mean this doesn't require an allocation on quite every function call, it means a good portion of function calls do allocate series.  This stresses the GC, but, I've mentioned how it was important for many reasons (including that the data stack memory isn't stable, and that meant the previous approach had bugs passing pointers to arguments around.  It's a given that this is how things are done now--especially with stackless--so it just needs to be designed around and tuned.</p>
</li>
<li>
<p><strong>WORD!s are special cases of string series.</strong>  Things like the word table and binding didn't count in series memory before, and wasn't tabulated in R3-Alpha in the series count.  There are some other examples of this.</p>
</li>
<li>
<p><strong>ACTION!s create more series and contexts.</strong>  The HELP information for most actions that have help information has two objects linked to it...one mapping parameter names to datatypes, and one mapping parameter names to descriptions.  I'm hoping that the one mapping parameter names to datatypes can be covered by the parameter information that the interpreter also sees...but for today, there's a difference because one contains TYPESET!s and the other contains human-readable BLOCK!s.</p>
</li>
<li>
<p><strong>So Much More Is Done In Usermode.</strong>  Ranging from console code to command-line argument processing, there's more source code (which counts as series itself) and more code running.</p>
</li>
</ul>
<p>I see it as good--not bad--that a ton of things run in the boot process.  Although I think you should be able to build an run a minimal system...even one that doesn't waste memory on HELP strings (it's now easier to make such things, since the spec isn't preserved).</p>
<p>But for today, the closest we have to a "minimal build" is the web build.  It's a bit more comparable to R3-Alpha in terms of how much startup code it runs.</p>
<h2>The Current State</h2>
<p>Starting up R3-Alpha on Linux, I get the following for <strong>stats/profile</strong>:</p>
<pre><code>r3-alpha&gt;&gt; stats/profile
== make object! [
    timer: 0:00:02.639939
    evals: 20375
    eval-natives: 3340
    eval-functions: 369
    series-made: 8393
    series-freed: 2597
    series-expanded: 70
    series-bytes: 2211900
    series-recycled: 2526
    made-blocks: 5761
    made-objects: 64
    recycles: 1
]
</code></pre>
<p>Ren-C on the web is considerably heavier, at least when it comes to evals + series made + GC churn <em>(a little less overall series bytes...probably mostly owed to optimizations that fit small series into the place where tracking information would be stored if it were a larger one)</em>:</p>
<pre><code>ren-c/web&gt;&gt; stats/profile
== make object! [
    evals: 65422
    series-made: 28569
    series-freed: 11160
    series-expanded: 419
    series-bytes: 1731611
    series-recycled: 8669
    made-blocks: 16447
    made-objects: 109
    recycles: 229  ; !!! see update, this is now 1
]
</code></pre>
<p>The increased number of evals just goes with the "a lot more is done in usermode" bit.  There's lots of ways to attack that if it's bothersome.</p>
<p>The series-made number is much bigger.  8393 v. 28569.  I mentioned how a lot of this is going to come from the fact that many evals need to make series, but we don't really have a breakdown of that number here to be sure that's accounting for them.  Anyway, this number isn't all that bothersome to me given that knowledge...but it should be sanity-checked.</p>
<p>What does bother me is the 229 recycles.  That's a lot.  Despite making 3-4x as many series, I don't see how exactly that's translating into 200x the recycling.</p>
<p><strong>UPDATE: This was the result of accidentally committed debug code.  It's back to 1.</strong></p>
<h2>Writing Down The Current State is Better Than Nothing</h2>
<p>Ideally we'd have some kind of performance regression chart that plotted some of these numbers after each build.  Though really it's not too worth doing that unless the numbers carried more information that was more actionable.</p>
<p>But...lacking an automated method, writing it down now and having a forum thread to keep track of findings and improvements is better than nothing.</p>
<p>There's likely a lot that could be done to help the desktop build (such as obviously tending to that encap-reading issue).  But I'd like to focus principally on improvements to the internals that offer benefit to the web build, where I think the main relevance is.  And:</p>
<ul>
<li>
<p><strong>Having a system built from rigorously understood invariants is the best plan for optimization over the long-term.</strong>  If you don't have a lot of assertions and confidence about what is and isn't true around your codebase, you can't know if a rearrangement will break it or not.  So I spend a lot of time focusing on defining these invariants and making sure they are true.</p>
</li>
<li>
<p><strong>Avoid optimizing things before you're sure if they're right.</strong>  I'm guilty as anyone of fiddling with things for optimization reasons just because it's cool or I get curious of whether something can work or not.  Programmers are tinkerers and that's just how it is.  But it's definitely not time to go over things with a fine-toothed comb when so many design issues are not worked out.</p>
</li>
</ul>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://forum.rebol.info/t/web-build-performance-stats/1468">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/web-build-performance-stats/1468</link>
          <pubDate>Mon, 18 Jan 2021 06:51:16 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1468</guid>
          <source url="https://forum.rebol.info/t/web-build-performance-stats/1468.rss">Web Build Performance Stats</source>
        </item>
        <item>
          <title>Moving Away From &quot;NULL termination&quot; (END!) of BLOCK!s</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>Ren-C preserved an idea from R3-Alpha...which was that there would be a cell type byte reserved to signal the end of an array.  This is a bit like how null terminators are used with C strings.  However, arrays also tracked their length.  So it was somewhat redundant information.</p>
<p>In R3-Alpha, the special cells were given the END! datatype.  Sometimes you would see bugs that would leak the existence of this internal type to the user.  Ren-C hid it more effectively, by not making it an actual "type".</p>
<p>On the plus side, this provides a clean-looking way to walk through the values in an array:</p>
<pre><code>REBVAL *item = ARR_HEAD(array);  // first cell pointer in the array
for (; NOT_END(item); ++item) {
    ...
}
</code></pre>
<p>However, there are several downsides:</p>
<ul>
<li>
<p><strong>You have to pay for a dereference on each step.</strong>  item is a pointer, and you have to follow that pointer to its memory location to read a byte there to see if you've reached the end.  This probably isn't <em>that</em> bad, because odds are you are going to be working with that memory inside the loop anyway.  But maybe you aren't...and you certainly aren't going to be for the last cell.</p>
</li>
<li>
<p><strong>You typically wind up paying a cell's worth of cost for this convenience.</strong>  If your array is empty, it still needs space for at least one cell.  If your array has one cell, it needs space for two.  If it has two it needs space for three, etc.  This isn't just an extra byte (as in C '\0' termination)...it's 4 platform pointers.  So 32 bytes of oft-wasted space on 64-bit platforms for a mostly empty cell.</p>
</li>
<li>
<p><strong>But rounding up by 1 is even worse than wasting one cell...</strong> because it propagates to rounding up in the memory pool block size, and memory pools are sized in multiples of 2 (2, 4, 8, 16, etc).  So if what you really want is a two-cell array--e.g. enough for <strong>a/b</strong>, you move up to the next size and take a chunk from the 4-cell pool.  A 4-cell array needs to come from the 8-cell pool.  Etc.</p>
</li>
</ul>
<h2>Should We Scrap This Idea?</h2>
<p>It's bothered me for a while, but since it might make enumeration faster in some cases I've let it hang around.  Having a terminator has helped catch out of bounds cases more easily.</p>
<p><strong>But I think the time has come to demote termination to a debug-build-only practice.</strong>  It's gotten in the way of too many interesting optimizations.</p>
<p>Data point: Red doesn't do it.  They just store the pointer to the tail of the data (in the slot where R3-Alpha stored the length).  It works either way since you can calculate the length by subtracting the head from the tail...or calculate the tail by adding the length to the head.  I'd imagine the tail is needed more often.</p>
<p>The code isn't usually that much worse:</p>
<pre><code>RELVAL *item = ARR_HEAD(array);  // "relative value", vs. REBVAL*
RELVAL *tail = ARR_TAIL(array);
for (; item != tail; ++item) {
    ...
}
</code></pre>
<p>But sometimes there were cases that a function would be passed a RELVAL* resident in an array, without passing the array also.  And then it would enumerate that value forward until it reached an end.  Such routines aren't all that common, but a few do exist.  They'd need to be revisited.</p>
<p>It's not that huge a deal, and kind of trivial in the scheme of things.  But it would touch a lot of code.  <img src="https://forum.rebol.info/images/emoji/twitter/frowning.png?v=9" title=":frowning:" class="emoji" alt=":frowning:">  But, as usual in Ren-C...the asserts can keep it running.</p>
<h2>END cells would still exist</h2>
<p>The END cell type is important for other reasons.  It's used in rebEND as a terminator for C va_list arguments, and that's not going away.  There are other applications which are beyond the scope of this post to explain.</p>
<p>And as I say, termination of some kind would probably continue in debug builds.  So they might over-allocate to have enough room at the tail to put an end cell, just to get errors to trigger if you went past the limit.</p>
<p>So let's not malign the END marker too much.  It has been a valuable contributor.  <img src="https://forum.rebol.info/images/emoji/twitter/medal_sports.png?v=9" title=":medal_sports:" class="emoji" alt=":medal_sports:"></p>
            <p><small>3 posts - 1 participant</small></p>
            <p><a href="https://forum.rebol.info/t/moving-away-from-null-termination-end-of-block-s/1445">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/moving-away-from-null-termination-end-of-block-s/1445</link>
          <pubDate>Wed, 30 Dec 2020 10:29:18 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1445</guid>
          <source url="https://forum.rebol.info/t/moving-away-from-null-termination-end-of-block-s/1445.rss">Moving Away From &quot;NULL termination&quot; (END!) of BLOCK!s</source>
        </item>
        <item>
          <title>&quot;HEART BYTES&quot;, Explained</title>
          <dc:creator><![CDATA[hostilefork]]></dc:creator>
          <category>Optimization</category>
          <description><![CDATA[
            <p>For those who've looked at Rebol sources, you know that a Rebol cell is the size of <em>four platform pointers</em>.</p>
<p>Ren-C keeps the general gist, with some important adjustments.  It breaks down as:</p>
<ul>
<li>
<p><strong>header:</strong> one pointer-sized integer (uintptr_t).  This tells you the cell's type (e.g. REB_BLOCK, REB_INTEGER), among other things.  Only 32 bits are used of this (operated on through <code>uint_fast32_t</code> alias field, in case 32-bit masking operations are faster on 64-bit platforms than a 64-bit <code>uintptr_t</code>).  This allows the system to function identically on 32 and 64 bit systems...though the extra 32 bits could be applied to some kind of 64-bit optimization purpose.  <em>{This post is regarding a proposal about how to use one of the 4 critical bytes in this header, differently from how it has been used so far.}</em></p>
</li>
<li>
<p><strong>"extra"</strong>: one pointer or pointer-sized integer.  It's a union, and which of the union fields is active depends on the type of the cell.  For "bindable" types, this holds a <em>binding</em>...and that's a fairly deep topic.  But if a type isn't bindable--let's say a MONEY! or a DATE!, then it can just use this for some spare bits to help put more data in the cell without needing to do a dynamic allocation.</p>
</li>
<li>
<p><strong>"payload"</strong>: Also a union that depends on the type of cell, but this one is the size of <em>two</em> platform pointers.  That makes it sufficient to hold something like a 64-bit floating point number on 32-bit platforms.  It comes after the "extra" on purpose--so that as long as the cell is on a 64-bit boundary, then on 32-bit platforms this payload will be on a 64-bit boundary as well.  (That's important.)</p>
</li>
</ul>
<p>Beyond just alignment, there's a lot of nuance to cells, and staying on the right side of the standard.  Being able to assign different datatype payloads but still use generic routines on the binding, being able to assign the header in one instruction without breaking strict aliasing.  There's comments in the code if people want to go down a rabbit hole.</p>
<p>But the main thing to take away is that you're not paying a catastrophic cost for something like a 64-bit integer in a Rebol array.  It's 2x the size it would be otherwise.  Fatter than a low-level C type, sure...but all the bits are right there with good locality...you don't have to go through a dereference to some malloc()'d entity.  Not much of a big deal.</p>
<h2>Despite Optimizations, <em>Arrays Cost Notably More</em>
</h2>
<p>When we try to understand the difference between <strong>[1 2 3]</strong> and <strong>[[1] [2] [3]]</strong>, just how much of cost is that in bytes or processing overhead?  If you're designing a dialect, should you fear BLOCK!s, GROUP!s, and PATH!s?</p>
<p>Well, when you've got that cell and the header says it's a REB_BLOCK, the "extra" field is used for stuff I'm not going to explain here.  But the Reb_Block_Payload union contains to two things: a <em>series node</em> pointer and the index that series value has in the block.</p>
<p>Series nodes are fixed-size tracking entities.  Though they're pretty small, they're still <em>eight platform pointers</em>.  To get to the node from the cell you have to hop through the pointer to another memory location, and so that's going to affect caching.</p>
<p>If you have a block of length 1 or 0, then Ren-C has a very neat optimization called "singular arrays".  The payload for the array lives <em>directly in the series node</em>.  Careful mechanics allow this to work, not breaking any alignment or aliasing rules, and even managing to wedge an array terminator into control bits used for other purposes.</p>
<p>So in this case--if you're lucky--you've gone from taking 4 platform pointers for just the REB_INTEGER cell, to a REB_BLOCK cell of 4 platform pointers...and a series node of 8 pointers.  3x the size for <strong>[1]</strong> vs. just <strong>1</strong>.</p>
<p>But let's say instead of a block, you were doing a PATH!, like the proposed 2-element path for <strong>/refinement</strong> (a BLANK! that's not rendered, and then the WORD! "refinement").  What would a 2-element array cost?</p>
<p>You've still got the 4 pointer cell and the 8 pointer series node.  But now you need a dynamic allocation to hold the 2 cells, so that would be 8 more platform pointers.</p>
<blockquote>
<p>Note: It would have needed to be 4 cells when a terminator was needed...but <a href="https://forum.rebol.info/t/moving-away-from-null-termination-end-of-block-s/1445">the terminator no longer applies</a>!  So arrays of length 2 can really just use 8 cells in their allocation now.  <img src="https://forum.rebol.info/images/emoji/twitter/partying_face.png?v=9" title=":partying_face:" class="emoji" alt=":partying_face:"></p>
</blockquote>
<p><em>Grand Total:</em> 4 + 8 + 8 =&gt; <strong>20 platform pointers</strong>...for something that took only 4 before!  So <strong>[1 1]</strong> is 5x as big as <strong>1</strong>, and on a 64-bit platform we're talking 160 bytes.  For a refinement like <strong>[_ refine]</strong> that's not even counting the storage for the UTF-8 name of the refinement and overhead for that...this is how much it costs just to <em>point</em> to it!</p>
<p>I'm neglecting all the overhead that dynamic allocation systems have to keep for their internal bookkeeping.  Plus, remember that locality...spreading this data out is about more than just how many bytes you use, it's <em>where</em> the bytes are.</p>
<h2>My Solution: "Heart Bytes"</h2>
<p>There's clearly no generic way to contain an arbitrary cell-sized thing inside a cell without adding cost.  It would be like zipping a zip file and guaranteeing it would always be smaller.  :-/</p>
<p>But if cells were willing to sacrifice some of their header bits, those bits might hold a key to allowing <strong>a</strong> and <strong>[a]</strong> to both fit into a single cell...as long as that cell wasn't <em>also</em> trying to be a 1-element array (e.g. [[a]]).  The extra and payload bits would line up with the the WORD!, but the same cell bits could be seen in one light as a BLOCK!, and in another light as a WORD!.</p>
<p>This sounds like a paradox.  How can it have an answer to VAL_TYPE(...) which is both REB_BLOCK and REB_WORD (!)  It would seem to have to be one thing or the other.</p>
<p><em><strong>Answer: Use the type system.</strong></em>  If you're holding the pointer via a plain REBVAL* to the cell, have it say this is a REB_BLOCK.  But if you're holding another pointer type (call it a REBCEL for now), then a REBCEL* would refuse to answer VAL_TYPE()...you'd get a compiler error if you tried.  Instead you'd have to ask for the HEART_BYTE().  Then the game becomes figuring out how and when to flip your pointers back and forth between REBVAL and REBCEL.</p>
<h2>Stating The Obvious (?): Only Works for Immutable Arrays</h2>
<p>You can't dodge the allocation of a separate entity outside the cell if you want multiple cell references to be able to make shared changes, or see changes made through one reference via another one.</p>
<p>If you try to apply this optimization on plain code, it couldn't do what you'd expect:</p>
<pre><code> &gt;&gt; block: [a]  ; one element, right on, optimize it right into that cell!
 &gt;&gt; ref: block  ; now both referring to the "same block"
 &gt;&gt; append block 'b
 ** Script Error: series is const ;-- oops, oh yeah, I'll just use MUTABLE

 &gt;&gt; append mutable block 'b
 ??? ;-- how could ref ever see a change, if only cells are exchanged?
</code></pre>
<p>The LOCK process could go through and do some compression, and there could be primitives for making these immutable blocks if you wanted them.  But they shouldn't be the default.</p>
<p><em>Unless...</em> they are loaded into a PATH!.  If we got people on board with the expectation that not only are paths immutable, but embedded groups and arrays are immutable <em>at least at the top level</em>, then this could work.</p>
<p>I discuss how this could really tie down <a href="http://forum.rebol.info/t/taming-the-pathology-of-path/1006">some of the more egregious ambiguities in PATH!</a>, making it a solid and reliable part for dialecting--something it has certainly not been in the past.  If we can kill off things like <strong><code>a/:b:</code></strong> in favor of <strong><code>a/(b):</code></strong> and pay no more for it, we very well may should.</p>
<blockquote>
<p>Update: Not only are we on board, but immutable paths and tuples and such are working fine!</p>
</blockquote>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://forum.rebol.info/t/heart-bytes-explained/1008">Read full topic</a></p>
          ]]></description>
          <link>https://forum.rebol.info/t/heart-bytes-explained/1008</link>
          <pubDate>Fri, 11 Jan 2019 05:13:22 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">forum.rebol.info-topic-1008</guid>
          <source url="https://forum.rebol.info/t/heart-bytes-explained/1008.rss">&quot;HEART BYTES&quot;, Explained</source>
        </item>
  </channel>
</rss>
